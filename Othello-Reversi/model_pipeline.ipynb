{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525af7d72e885e78",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training a specialised model (CNN+RNN) for Othello/Reversi\n",
    "\n",
    "This notebook presents a way to estimate the next move to play in a game of Othello using Supervised Learning. The datasets come from the [Fédération Française d'Othello](https://www.ffothello.org/informatique/la-base-wthor/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14453e6bec3cf95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312111970ff9bc18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:44.650143Z",
     "start_time": "2024-04-13T20:18:44.647434Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import struct   # for reading the .wtb files\n",
    "import os       # for file/path/directories,...  handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b56767f2f2a65",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Extracting data from the WThor database\n",
    "\n",
    "Some functions were taken or modified from the [dnnothello repo](https://github.com/wjaskowski/dnnothello/blob/master/games/othello_data.py)\n",
    "\n",
    "The header of a .wthor file is 16 bytes long and contains the following fields:\n",
    "- 1 byte: century of the file's creation\n",
    "- 1 byte: year of the file's creation\n",
    "- 1 byte: month of the file's creation\n",
    "- 1 byte: day of the file's creation\n",
    "- 4 bytes (int): number of games in the file ($\\leq$ 2 147 483 648)\n",
    "- 2 bytes (short): 0 here (but for other type of files : number of players, tournaments, or number of empty squares in the board ($\\leq$ 65 535))\n",
    "- 1 byte: year of the games\n",
    "- 1 byte: size of the board {0: 8x8, 8: 8x8, 10: 10x10}\n",
    "- 1 byte: 0 here the games type (1 if \"solitaire\", 0 otherwise)\n",
    "- 1 byte: the games depth\n",
    "- 1 byte: reserved\n",
    "\n",
    "The games are stored in the file in the following format:\n",
    "- 2 bytes (short): label of the tournament\n",
    "- 2 bytes (short): id number of the black player\n",
    "- 2 bytes (short): id number of the white player\n",
    "- 1 byte: true score of the black player\n",
    "- 1 byte: theoretic score of the black player\n",
    "\n",
    "And then each move is stored as a 60 byte long record (list of moves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f5dc444f692047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:44.693228Z",
     "start_time": "2024-04-13T20:18:44.687256Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 8\n",
    "\n",
    "HEADER_LENGTH = 16\n",
    "HEADER_FORMAT = \"<BBBBIHHBBBB\"  # Byte, Byte, Byte, Byte, Int, Short, Short, Byte, Byte, Byte, (Reserved) Byte\n",
    "\n",
    "GAME_INFO_LENGTH = 8    \n",
    "GAME_INFO_FORMAT = \"<HHHBB\"     # Short, Short, Short, Byte, Byte\n",
    "\n",
    "MOVES_LENGTH = 60\n",
    "MOVES_FORMAT = \"<\" + \"B\"*MOVES_LENGTH\n",
    "\n",
    "POSSIBLE_SIZE = [0, 8]\n",
    "\n",
    "def read_all_wtb_files(directory):\n",
    "    \"\"\"Generator to read all .wtb files in a directory.\"\"\"\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".wtb\"):\n",
    "            yield from read_wtb(os.path.join(directory, file_name))\n",
    "\n",
    "def read_wtb(file_path):\n",
    "    \"\"\"Generator to read a .wtb file and yield game information and played moves.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        header = struct.unpack(HEADER_FORMAT, f.read(HEADER_LENGTH))\n",
    "        assert header[7] in POSSIBLE_SIZE   # Check the board size\n",
    "        \n",
    "        for _ in range(header[4]):  # Number of games\n",
    "            game_info = struct.unpack(GAME_INFO_FORMAT, f.read(GAME_INFO_LENGTH))\n",
    "            played_moves = struct.unpack(MOVES_FORMAT, f.read(MOVES_LENGTH))\n",
    "            yield game_info[3], played_moves    # Black player true score, moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b0357eab45455b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:44.742183Z",
     "start_time": "2024-04-13T20:18:44.737169Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, (56, 64, 53, 46, 35, 63, 34, 66, 65, 74, 37, 43, 57, 33, 76, 24, 75, 26, 83, 36, 73, 38, 25, 16, 14, 15, 17, 47, 13, 68, 48, 58, 52, 28, 67, 23, 12, 61, 32, 42, 31, 86, 51, 41, 27, 84, 85, 82, 71, 18, 72, 11, 21, 22, 62, 81, 77, 78, 88, 87))\n",
      "(34, (56, 64, 33, 36, 46, 34, 43, 67, 66, 65, 53, 63, 74, 84, 75, 57, 35, 24, 47, 38, 76, 52, 58, 37, 42, 62, 83, 82, 73, 85, 86, 87, 48, 68, 25, 14, 13, 31, 61, 51, 15, 26, 77, 23, 41, 88, 21, 72, 16, 32, 12, 22, 78, 71, 81, 11, 17, 27, 28, 18))\n"
     ]
    }
   ],
   "source": [
    "reader = read_wtb('data/raw/WTH_2001.wtb')\n",
    "print(next(reader))\n",
    "\n",
    "full_reader = read_all_wtb_files('data/raw')\n",
    "print(next(full_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a907dfa7c46a319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.325017Z",
     "start_time": "2024-04-13T20:18:44.761729Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.bitwise_func import set_state, cell_count\n",
    "from node import Node, replay\n",
    "from game import init_bit_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe3aacf8f0431e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.335204Z",
     "start_time": "2024-04-13T20:18:46.327944Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_game(moves):\n",
    "    \"\"\"Decode moves played in a game from the board representation to the bitboard representation.\"\"\"\n",
    "    enemy, own = init_bit_board(BOARD_SIZE)\n",
    "    node = Node(None, own, enemy, -1, BOARD_SIZE, -1)\n",
    "    for move in moves:\n",
    "        if move == 0:\n",
    "            break\n",
    "        node.expand() # Generate the possible moves\n",
    "        x, y = decode_move(move)\n",
    "        move = set_state(0, x, y, BOARD_SIZE)\n",
    "        \n",
    "        if move not in node.moves: # then it means it is a pass and the other player plays, or it is the end of the game\n",
    "            node.invert()\n",
    "            node.expand()\n",
    "            if move in node.moves:\n",
    "                node = node.set_child(move)\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            node = node.set_child(move)\n",
    "    return node\n",
    "\n",
    "            \n",
    "def decode_move(move):\n",
    "    \"\"\"Decode a move from the board representation to the (x, y) representation.\"\"\"\n",
    "    return move // 10 - 1, move % 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7300e7eb571e10f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.381086Z",
     "start_time": "2024-04-13T20:18:46.337152Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected score: 52\n",
      "Score : (52, 12)\n",
      "Expected score: 64\n",
      "Score : (63, 0)\n"
     ]
    }
   ],
   "source": [
    "true_score, game_moves = next(full_reader)\n",
    "print(f\"Expected score: {true_score}\")\n",
    "first_game = decode_game(game_moves)\n",
    "# replay(first_game, BOARD_SIZE)\n",
    "print(f\"Score : {cell_count(first_game.own_pieces), cell_count(first_game.enemy_pieces)}\") if first_game.turn == -1 else print(f\"Score : {cell_count(first_game.enemy_pieces), cell_count(first_game.own_pieces)}\")\n",
    "while true_score in [cell_count(first_game.own_pieces), cell_count(first_game.enemy_pieces)]:\n",
    "    true_score, game_moves = next(full_reader)\n",
    "    first_game = decode_game(game_moves)\n",
    "print(f\"Expected score: {true_score}\")\n",
    "print(f\"Score : {cell_count(first_game.own_pieces), cell_count(first_game.enemy_pieces)}\") if first_game.turn == -1 else print(f\"Score : {cell_count(first_game.enemy_pieces), cell_count(first_game.own_pieces)}\")\n",
    "# replay(first_game, BOARD_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e49a4debca08c4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "True score is the number of pieces of the black player + the empty ones if he won, or only the number of pieces if he lost. The score is always given from the black player's perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98443fb3a4514aff",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8831c3c4aeb0e2c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.398222Z",
     "start_time": "2024-04-13T20:18:46.383046Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def node_to_board(node: Node) -> np.ndarray:\n",
    "    \"\"\"Convert a Node object to a numpy array.\"\"\"\n",
    "    board = np.zeros((BOARD_SIZE, BOARD_SIZE))\n",
    "    for i in range(BOARD_SIZE):\n",
    "        for j in range(BOARD_SIZE):\n",
    "            if node.own_pieces & (1 << (i * BOARD_SIZE + j)):\n",
    "                board[i, j] = node.turn\n",
    "            elif node.enemy_pieces & (1 << (i * BOARD_SIZE + j)):\n",
    "                board[i, j] = -node.turn\n",
    "    return board\n",
    "\n",
    "def bitboardMove_to_x_y(move: int) -> (int, int):\n",
    "    \"\"\"Convert a move from the bitboard representation to the (x, y) representation.\"\"\"\n",
    "    for i in range(BOARD_SIZE):\n",
    "        for j in range(BOARD_SIZE):\n",
    "            if (move & (1 << (i * BOARD_SIZE + j))) != 0:\n",
    "                return i, j\n",
    "    return -1, -1\n",
    "\n",
    "def find_move(current_node: Node, next_node: Node) -> (int, int):\n",
    "    \"\"\"Find the move that was played between two nodes.\"\"\"\n",
    "    for move in current_node.moves:\n",
    "        if current_node.set_child(move) == next_node:\n",
    "            # convert the binary move to (x, y) representation\n",
    "            return bitboardMove_to_x_y(move)\n",
    "    return -1, -1\n",
    "\n",
    "def dump_data(directory, output_file_black, output_file_white, batch_size=1000):\n",
    "    data_black = []\n",
    "    data_white = []\n",
    "    batch_count_black = 0\n",
    "    batch_count_white = 0\n",
    "    i = 0\n",
    "    data_reader = read_all_wtb_files(directory)\n",
    "    \n",
    "\n",
    "    for (score, moves) in data_reader:\n",
    "        game = decode_game(moves)\n",
    "        move_list = replay(game, BOARD_SIZE, False)\n",
    "        for j in range(len(move_list) - 1):\n",
    "            current_node = move_list[j]\n",
    "            next_node = move_list[j + 1]\n",
    "            current_board = node_to_board(current_node)\n",
    "            next_move = find_move(current_node, next_node)\n",
    "            \n",
    "            if next_move == (-1, -1):\n",
    "                continue\n",
    "            \n",
    "            # Append Black moves to the data of the black player if he won, and to the data of the white player otherwise\n",
    "            if score >= 32:\n",
    "                data_black.append((current_board, next_move))\n",
    "            else:\n",
    "                data_white.append((current_board, next_move))\n",
    "\n",
    "            if len(data_black) == batch_size:\n",
    "                with open(f'{output_file_black}_batch_{batch_count_black}.pkl', 'wb') as f:\n",
    "                    pickle.dump(data_black, f)\n",
    "                print(f\"Dumped batch {batch_count_black} to file after processing {i + 1} games, total {len(data_black)} samples.\")\n",
    "                data_black = []  # Reset data for the next batch\n",
    "                batch_count_black += 1\n",
    "            if len(data_white) == batch_size:\n",
    "                with open(f'{output_file_white}_batch_{batch_count_white}.pkl', 'wb') as f:\n",
    "                    pickle.dump(data_white, f)\n",
    "                print(f\"Dumped batch {batch_count_white} to file after processing {i + 1} games, total {len(data_white)} samples.\")\n",
    "                data_white = []  # Reset data for the next batch\n",
    "                batch_count_white += 1\n",
    "        i += 1\n",
    "\n",
    "    # Dump any remaining data not fitting the batch size\n",
    "    if data_black:\n",
    "        with open(f'{output_file_black}_batch_{batch_count_black}.pkl', 'wb') as f:\n",
    "            pickle.dump(data_black, f)\n",
    "        print(f\"Dumped final batch {batch_count_black} to file, total {len(data_black)} samples.\")\n",
    "    if data_white:\n",
    "        with open(f'{output_file_white}_batch_{batch_count_white}.pkl', 'wb') as f:\n",
    "            pickle.dump(data_white, f)\n",
    "        print(f\"Dumped final batch {batch_count_white} to file, total {len(data_white)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cb1c655d12f4b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.407238Z",
     "start_time": "2024-04-13T20:18:46.402135Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dump_data('data/raw', 'data/black/data', 'data/white/data', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5665b7a476e03002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.415903Z",
     "start_time": "2024-04-13T20:18:46.409199Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black data size: 3847000\n",
      "White data size: 3682000\n"
     ]
    }
   ],
   "source": [
    "black_data_size = 3847 * 1000\n",
    "white_data_size = 3682 * 1000\n",
    "print(f\"Black data size: {black_data_size}\")\n",
    "print(f\"White data size: {white_data_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3431c9debe3646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.457914Z",
     "start_time": "2024-04-13T20:18:46.417862Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3847 3682\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Dataset class for Othello (credits to https://github.com/zatomos for coming up with this absolute masterpiece of a name)\n",
    "class Othelload(Dataset):\n",
    "    def __init__(self, file_list, nb_samples_by_file):\n",
    "        self.file_list = file_list\n",
    "        self.nb_samples_by_file = nb_samples_by_file\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list) * self.nb_samples_by_file\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            # Get the corresponding file\n",
    "            file_index = index // self.nb_samples_by_file\n",
    "            file = self.file_list[file_index]\n",
    "            # Get the corresponding sample\n",
    "            sample_index = index % self.nb_samples_by_file\n",
    "            with open(file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            board, move = data[sample_index]\n",
    "            # convert the board to a 32 float tensor. Convert the move (x,y) to one hot encoding\n",
    "            board = torch.tensor(board, dtype=torch.float32).unsqueeze(0)\n",
    "            move = torch.tensor(move[0] * 8 + move[1], dtype=torch.long)\n",
    "            return board, move\n",
    "        except Exception as e:\n",
    "            print(f\"Error while generating pair (sample, label) at index {index}\\n{e}\")\n",
    "            raise e\n",
    "    \n",
    "# Create the dataset\n",
    "file_list_black = glob.glob('data/black/data*.pkl')\n",
    "file_list_white = glob.glob('data/white/data*.pkl')\n",
    "print(len(file_list_black), len(file_list_white))\n",
    "othelload_black = Othelload(file_list_black, nb_samples_by_file=1000)\n",
    "othelload_white = Othelload(file_list_white, nb_samples_by_file=1000)\n",
    "\n",
    "# Create the dataloaders\n",
    "dataloader_black = DataLoader(othelload_black, batch_size=8, shuffle=True)\n",
    "dataloader_white = DataLoader(othelload_white, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a797210bb866d6",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee964899d1908364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.470176Z",
     "start_time": "2024-04-13T20:18:46.458896Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model definition : Let's start simple, just a CNN with 8 conv layers (+BN and Relu) and 2 FC layers\n",
    "# conv64 → conv64 → conv128 → conv128 → conv256 → conv256 → conv256 → conv256 → f c128 → f c60\n",
    "class OthelloNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OthelloNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = x.view(-1, 256 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6878a03c2651f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:46.775875Z",
     "start_time": "2024-04-13T20:18:46.472137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [8, 64, 8, 8]             640\n",
      "       BatchNorm2d-2              [8, 64, 8, 8]             128\n",
      "            Conv2d-3              [8, 64, 8, 8]          36,928\n",
      "       BatchNorm2d-4              [8, 64, 8, 8]             128\n",
      "            Conv2d-5             [8, 128, 8, 8]          73,856\n",
      "       BatchNorm2d-6             [8, 128, 8, 8]             256\n",
      "            Conv2d-7             [8, 128, 8, 8]         147,584\n",
      "       BatchNorm2d-8             [8, 128, 8, 8]             256\n",
      "            Conv2d-9             [8, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-10             [8, 256, 8, 8]             512\n",
      "           Conv2d-11             [8, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-12             [8, 256, 8, 8]             512\n",
      "           Conv2d-13             [8, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-14             [8, 256, 8, 8]             512\n",
      "           Conv2d-15             [8, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-16             [8, 256, 8, 8]             512\n",
      "           Linear-17                   [8, 128]       2,097,280\n",
      "           Linear-18                    [8, 64]           8,256\n",
      "================================================================\n",
      "Total params: 4,432,768\n",
      "Trainable params: 4,432,768\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 11.01\n",
      "Params size (MB): 16.91\n",
      "Estimated Total Size (MB): 27.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(OthelloNet().cuda(), (1, 8, 8), batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "420df55dce2591b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:47.998806Z",
     "start_time": "2024-04-13T20:18:46.776857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define criterion, optimizer and scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "model = OthelloNet()\n",
    "\n",
    "# Define the criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the scheduler : decrease the learning rate by a factor of 10 every 10 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b47d4c274bbf573a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:48.758374Z",
     "start_time": "2024-04-13T20:18:47.999788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 3269950\n",
      "Number of samples in the validation set: 384700\n",
      "Number of samples in the test set: 192350\n"
     ]
    }
   ],
   "source": [
    "# Create Training, Validation, and Test sets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Define the percentage of samples for each set\n",
    "validation_split = 0.1\n",
    "test_split = 0.15\n",
    "\n",
    "# Define the indices\n",
    "dataset_size = len(othelload_black)\n",
    "indices = list(range(dataset_size))\n",
    "split1 = int(np.floor(validation_split * dataset_size))\n",
    "split2 = int(np.floor(test_split * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices, test_indices = indices[split2:], indices[:split1], indices[split1:split2]\n",
    "\n",
    "# Define the samplers\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# Define the dataloaders\n",
    "train_loader = DataLoader(othelload_black, batch_size=8, sampler=train_sampler)\n",
    "valid_loader = DataLoader(othelload_black, batch_size=8, sampler=valid_sampler)\n",
    "test_loader = DataLoader(othelload_black, batch_size=8, sampler=test_sampler)\n",
    "\n",
    "# Display the number of samples in each set\n",
    "print(f\"Number of samples in the training set: {len(train_indices)}\")\n",
    "print(f\"Number of samples in the validation set: {len(val_indices)}\")\n",
    "print(f\"Number of samples in the test set: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b35f565b31ef9f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:18:48.765760Z",
     "start_time": "2024-04-13T20:18:48.759357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a class to save best model and track the loss\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1c15f2407762572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:34:52.955389Z",
     "start_time": "2024-04-13T20:18:48.766745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Training:   6%|▌         | 23887/408744 [16:02<4:18:34, 24.81it/s, loss=4.08] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Adding tqdm for progress tracking in training loop\u001b[39;00m\n\u001b[0;32m     18\u001b[0m train_loader_pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (boards, moves) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader_pbar):\n\u001b[0;32m     20\u001b[0m     boards \u001b[38;5;241m=\u001b[39m boards\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move boards to GPU\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     moves \u001b[38;5;241m=\u001b[39m moves\u001b[38;5;241m.\u001b[39mto(device)    \u001b[38;5;66;03m# Move moves to GPU\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\ProjectsIA\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\ProjectsIA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\ProjectsIA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\ProjectsIA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\ProjectsIA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m, in \u001b[0;36mOthelload.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     23\u001b[0m sample_index \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_samples_by_file\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 25\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     26\u001b[0m board, move \u001b[38;5;241m=\u001b[39m data[sample_index]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# convert the board to a 32 float tensor. Convert the move (x,y) to one hot encoding\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "n_epochs = 100\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, path='data/model.pth')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    # Adding tqdm for progress tracking in training loop\n",
    "    train_loader_pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} Training\")\n",
    "    for i, (boards, moves) in enumerate(train_loader_pbar):\n",
    "        boards = boards.to(device)  # Move boards to GPU\n",
    "        moves = moves.to(device)    # Move moves to GPU\n",
    "\n",
    "        if any(moves < 0) or any(moves >= 64):\n",
    "            print(f\"Invalid move: {moves}\")\n",
    "            continue\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(boards)\n",
    "        loss = criterion(outputs, moves)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        # Update tqdm progress bar\n",
    "        train_loader_pbar.set_postfix(loss=running_loss / (i + 1))\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    # Adding tqdm for progress tracking in validation loop\n",
    "    valid_loader_pbar = tqdm(valid_loader, desc=f\"Epoch {epoch + 1}/{n_epochs} Validation\")\n",
    "    with torch.no_grad():\n",
    "        for i, (boards, moves) in enumerate(valid_loader_pbar):\n",
    "            boards = boards.to(device)  # Move boards to GPU\n",
    "            moves = moves.to(device)    # Move moves to GPU\n",
    "\n",
    "            if any(moves < 0) or any(moves >= 64):\n",
    "                print(f\"Invalid move: {moves}\")\n",
    "                continue\n",
    "\n",
    "            outputs = model(boards)\n",
    "            loss = criterion(outputs, moves)\n",
    "            val_loss += loss.item()\n",
    "            # Update tqdm progress bar\n",
    "            valid_loader_pbar.set_postfix(val_loss=val_loss / (i + 1))\n",
    "\n",
    "    val_loss /= len(valid_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Training loss: {running_loss / len(train_loader)}, Validation loss: {val_loss}\")\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    model.train()  # Ensure model is in training mode after evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e62d968ddf4ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T20:34:52.958324Z",
     "start_time": "2024-04-13T20:34:52.957347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.load_state_dict(torch.load('data/model.pth'))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (boards, moves) in enumerate(test_loader):\n",
    "        if any(moves < 0) or any(moves >= 64):\n",
    "            print(f\"Invalid move: {moves}\")\n",
    "            continue\n",
    "        outputs = model(boards)\n",
    "        loss = criterion(outputs, moves)\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11704b7716accd93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
